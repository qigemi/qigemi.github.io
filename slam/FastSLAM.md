---
layout: post
---

# FastSLAM: A Factored Solution to the Simultaneous Localization and Mapping Problem With Unknown Data Association(2003)

## 摘要

 Sebastian Thrun 在谷歌做自动驾驶，制作过一个公开课介绍了卡尔曼滤波和粒子滤波的定位方法，还有 python 实现。这篇文章，针对EKF计算量大和误匹配敏感的问题，将整个SLAM的后验概率表示分解为机器人路径和landmark的后验概率表示，用粒子滤波的方法实现一种SLAM。对路径点的采样可以降低计算复杂度，对数据关联（应该就是闭环）的采样可以增加鲁棒性。**主要特点是突出一个快**，当然距离今天也比较久远了。

## 1.综述

因为控制误差和测量误差的存在，定位和建图的误差是偶合在一起的，我们必须同时对机器人轨迹和地图进行估计。这导致 SLAM 问题比较复杂。本文将会把 SLAM 问题分解为几个容易解决的子问题。

一般状态估计是最大化后验概率。

* 已经有一些 SFM（Structure From Motion） 方法，将所有观测值放进一个目标函数整体优化，比如有一种方法，先恢复相机模型，然后用前两帧恢复摄影变换，再逐步选择其他帧结合已恢复的物体点恢复摄影变换，最后整体优化恢复仿射变换，得到一个相差尺度因子的重建结果。其实已经比较像现在流行的 track 加 loop 的 SLAM 方法。而且人们也发现了 SLAM 优化问题中 H 矩阵的稀疏性。当然这种方法的计算规模会越来越大，到时候需要一些边缘化的方法简化地图结构。所以本文还是采用滤波的方法。

SLAM 问题的后验概率可以表示为

$$p(s_t,\theta|z^t,u^t)$$

$s_t,\theta$ 分别表示机器人位姿和地图，$z^t,u^t$ 表示 t 时刻之前所有的测量值和控制指令。用 $z_t,u_t$ 等表示 t 时刻的测量和控制。一般地图可以用特征点（landmark）的位姿表示（现在也有线，面，语义等表示了）。这里是没有考虑数据关联（data associations）的，即测量只是看到一个新landmark而不识别是否是之前见过的landmark，如果已知每次观测到的是哪个landmark，这个信息用 $n^t$ 表示，则后验概率变为

$$p(s_t,\theta|z^t,u^t, n^t)$$

用贝叶斯公式可以得到递归的求解公式，也就是 SLAM 的贝叶斯滤波（Bayes Filter）解法，卡尔曼滤波和粒子滤波都是贝叶斯滤波的特殊形式。

$$p(s_t,\theta|z^t,u^t, n^t)=\eta p(z_t|s_t,\theta,n_t)\int p(s_t|s_{t-1},u_t)p(s_{t-1},\theta|z^{t-1},u^{t-1},n^{t-1})ds_{t-1}\tag{1.1}$$

EKF(Extended Kalman Filter) 方法对错误关联敏感，其计算复杂度是landmark数量的平方量级，但是因为距离较远的landmark之间关系比较弱，在协方差矩阵中可以忽略，所以一般EKF方法会在空间中画一个窗口，限制求解问题的大小。虽然这样可以限制计算复杂度，但错误关联问题还是不能解决。另一种思路是在时间上画窗口。

landmark 分布之间的关联性是因为路径的不确定性，假设机器人路径是已知的，则每个landmark之间的位姿分布应该是相互独立的。实际上 SLAM 后验概率可以分解为

$$p(s_t,\theta|z^t,u^t, n^t)=p(s_t|z^t,u^t, n^t)\prod_{n=1}^N p({\theta}_n|s^t,z^t,u^t,n^t)$$

左边的因子表示路径的条件概率分布，右边因子是所有landmark的依赖于路径的条件概率分布，它们是相互独立的，所以概率可以乘起来。注意这个公式的严格成立的，不是近似。

这种分解对应了本文所使用的方法。整体上是粒子滤波，每个粒子表示机器人的一种轨迹，每个粒子上有N个卡尔曼滤波器，对应N个landmark。每次根据控制指令，更新每个粒子的机器人位姿，然后根据测量值更新卡尔曼滤波器和landmark位姿。再给每个粒子赋上权重，根据权重冲采样，最终收敛。该方法复杂度是 log(N)，采样过程允许我们在不同点粒子中采用不同的数据关联，通过采样剔除错误关联，提升鲁棒性。

## 2.SLAM问题的分析和现有解法

可以整体上归纳为求最大后验概率，后验概率可以根据马尔科夫链的假设，贝叶斯公式和全概率公式进行分解，为式 (1.1) 的形式。但是该式的全概率积分部分没有解析解，所以目前的解法都会对后验概率，运动模型和测量模型做一些近似。

EKF就是将非线性的SLAM问题在最可能的状态点上线性化，近似用线性高斯系统表示。状态量是机器人位姿和所有landmark位姿，复杂度为landmark数量的平方。而且它对错误关联敏感，因为这种滤波的形式一旦错误关联加入滤波器，后面就无法消掉它的影响。

EKF不能直接应用在大规模的SLAM问题中，所以一般会用 submap 的方法，根据空间位置画窗口，每次EKF处理 submap，并在合适的时机优化整个地图。还有利用协方差矩阵的逆的稀疏性的方法等。它们基本可以达到线性时间复杂度甚至常数复杂度。

### 2.1 数据关联

计算当前观测的landmark是之前看过的landmark的概率，如果最大的概率大于某阈值则认为关联成功。很明显这种方法会有错误关联，尤其是传感器噪声大的时候，直观的方法是只有这个最大概率显著大的时候才认为正确，但这样会导致大量关联被拒绝，则更多landmark被创建，后面在确认关联会更加困难。有一些判断错误关联的方法。

1. 如果传感器噪声很大，则用大量不准确的测量综合估计一个准确的测量
2. 但是同一时间内的测量误差可能一样，且相邻时间内的测量也不是完全无关的，所以有一种考虑所有测量的方法，将所有可能的测量组合排列成一棵树，用分枝定界法找合理的组合，跟 alpha go 有点像。
3. 所有可能的关联构成一个无向图，节点是可能的（feature，landmark）组合，边是两种组合的一致性，最后找到图中的最大团，作为正确闭环。
4. 类似 EM 的迭代方法，先根据轨迹找最可能的匹配，然后根据匹配更新路径，如此迭代
5. 前几种都是从所有关联中选择正确的加入滤波器的，也有同时保存多种假设的方法。比如当出现可能错误的关联时，将每种关联方式分别加入滤波器，即增加“平行宇宙”，然后随时间删除错误的结果。或者在出现歧义的时候停止建图（因为每个EKF都要存所有的landmark，存多个EKF的话会很大，所以只在出现歧义时停止建图并计算），用粒子滤波确定了关联之后再继续。

FastSLAM 用每种可能的路径作为粒子，每个粒子上有N个卡尔曼滤波器，对应N个landmark，这样即减小时间复杂度，又可以保留多种关联假设，对错误关联鲁棒。

## 3. FastSLAM 1.0

再说一下总体框架，M 个粒子，每个粒子保存 0-t 时刻的机器位姿，以及 N 个landmark的位姿。先假设数据关联是已知的。粒子滤波的过程分为四个步骤：

1. 根据控制指令更新粒子中的机器位姿
2. 根据测量量更新所有粒子中的 EKF，也就是landmark位姿
3. 根据更新后的位姿计算每个粒子的权重
4. 根据权重重采样

#### 3.1.1 生成新位姿

根据控制指令和上一时刻的分布，估计当前时刻的位姿分布，并采样生成新位姿。运动更新可能是非线性的，卡尔曼滤波只能处理线性的运动更新，而粒子滤波可以处理这些非线性更新。

在二维平面上运动的机器人，控制指令只有线速度和角速度，其噪声可认为是高斯分布的，这种假设可以涵盖打滑的情况。但是控制指令的高斯分布传播到机器人位姿上就不一定是高斯的了，所以我们实际上在控制指令的分布上采样，得到采样结果后将其作用在机器位姿上得到当前的新位姿。而不是在位姿分布上采样。实验表明250个采样就挺好。

#### 3.1.2 更新landmark位姿

landmark位姿条件概率分布为：

$$p(\theta |s^t,z^t,u^t,n^t)=\eta p(z_t|\theta ,s^t,z^{t-1},u^t,n^t)p(\theta |s^t,z^{t-1},u^t,n^t)\\ =\eta p(z_t|\theta ,s^t,n^t)p(\theta |s^{t-1},z^{t-1},u^{t-1},n^{t-1})$$

用卡尔曼滤波更新。

#### 3.1.3 计算粒子权重

通过采样得到的机器人位姿分布是 $p1(s^t|z^{t-1},u^{t},n^{t-1})$，而实际的分布应该是 $p2(s^t|z^{t},u^{t},n^{t})$，我们通过加权采样从前者得到后者。还是在p1上采样，只不过当p2大于p1时，给较大的权重，反之给小权重。权重定义为：

$$\begin{align}
w_t&=\frac{p(s^t|z^{t},u^{t},n^{t})}{p(s^t|z^{t-1},u^{t},n^{t-1})}\\
&\overset{Bayes}\propto \frac{p(z_t|s^t,z^{t-1},u^t,n^t)p(s^t|z^{t-1},u^t,n^t)}{p(s^t|z^{t-1},u^t,n^{t-1})}\\
&\overset{Markov}=\frac{p(z_t|s^t,z^{t-1},u^t,n^t)p(s^t|z^{t-1},u^t,n^{t-1})}{p(s^t|z^{t-1},u^t,n^{t-1})}\\ &=p(z_t|s^t,z^{t-1},u^t,n^t)
\end{align}$$

这个概率从EKF可以解析的得到，实际上就是假设测量值服从高斯分布，根据估计的测量值和实际测量值的差计算概率。

### 3.2 数据关联

最大化似然概率求数据关联。但由于landmark位姿误差和机器位姿误差的存在，很容易出现错误关联。其中机器位姿误差导致的影响更大。

我们让每个粒子选择不同的数据关联，这样正确的关联会得到更高的似然，也就是权重，自动筛选出正确的关联。同时每个粒子代表的路径固定，也可以排除机器位姿误差的影响。这一优点在运动误差大而测量准确时更加明显。这样做隐式的使闭环滞后，因为可能先加入一个错误闭环，然后后面正确的闭环可能否决这一错误闭环，将其删除。

* 即使是图优化形式的SLAM也需要剔除错误闭环，我在工程中深有体会，要得到精度高（正确）的闭环，就需要牺牲一些实时性，二者不可得兼。用更多的测量来判断错误和提高精度，如果来一个闭环就加入，肯定是存在误差和错误的。除非环境友好，且有非常有效的、只凭一个闭环就能判断其正确与否的方法。

#### 3.2.1 每个粒子做最大似然估计

认为与观测到的位置马氏距离最小的landmark是闭环的landmark。如果这个距离大于某个阈值则添加新landmark。

#### 3.2.2 蒙特卡洛

虽然ML方法有更高的可能性选择正确的闭环，但是有一种情况就是它永远不会选择概率次大的闭环（该闭环可能才是正确的）。所以有蒙特卡洛方法，根据上述距离算概率，按照概率选择landmark作为闭环，也就是距离近的有更高的可能被选择。如果测量误差大，则会产生很多可能性，所以有人提出这种方法，先生成所有可能性，再根据似然采样出原来数量的粒子。这样相当于做了蒙特卡洛过程。

### 3.3 添加landmark

如果测量函数是可逆的，则可以通过一次测量确定landmark的位置，否则需要多次测量（比如单目SLAM），创建landmark时根据测量误差模型确定其位置误差，初始误差可以设置大一点，后面根据进一步测量逐步缩小。

### 3.4 两个trick

#### 3.4.1 数据关联时的贪婪算法

一般数据关联时认为同一时间的每个测量是独立的，但实际上同一时间看到的landmark不应该是同一个，在观测量很大时，考虑这种互斥性是比较费时的。fastSLAM采用贪心算法，即按顺序判断数据关联，同时保证互斥性。显然顺序是影响关联结果的，这一影响通过粒子滤波来消除，每个粒子用不同的顺序来关联。

#### 3.4.2 反面证据

如果我们在某个位置上，本来应该看到某个landmark，却没有看到，则可以认为该landmark创建错误（可能并不存在这个landmark）。我们给每个landmark计数，看到一次就加1，没看到就-1，小于某值就删除。这种方法跟激光雷达建障碍物地图一样！

## 3. FastSLAM 2.0
