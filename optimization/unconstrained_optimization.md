---
layout: post
---

# 1.无约束优化问题

先给定义，问题表示为

$$\min_{x}f(x)\\
where\ x\in\mathbb{R}^n,f:\mathbb{R}^n\rightarrow \mathbb{R}$$

这里我们考虑f是可微的。在找这个问题的解之前先明确什么样的点是该问题的一个解，即什么是极小值点。

- 如果对所有的x都有 $f(x^{*})\leqslant f(x)$，则称 $x^*$ 为全局极小值点。

- 如果在 $x^*$ 的邻域 $\mathcal N$ 内有 $f(x^*)\leqslant f(x),\forall x\in\mathcal N$，则称 $x^*$ 为局部极小值点。

- 如果 $f(x_0)<f(x),\forall x\in\mathcal N,x\neq x_0$，则x0称为严格局部极小值点。

全局极小值条件比较苛刻，我们先考虑局部较小值。看上去我们需要比较邻域内的所有函数值才能确定一个点是不是局部极小值点，实际上如果函数f是二阶连续可微的，我们可以通过函数梯度 $\nabla f$ 和黑塞矩阵 $\nabla^2f$ 来判定。

1. 一阶必要条件：$\nabla f(x_0)=0$
2. 二阶必要条件：$\nabla f(x_0)=0, \nabla^2f(x_0)$ 半正定
3. 二阶充分条件：$\nabla f(x_0)=0, \nabla^2f(x_0)$ 正定，则x0是严格极小值点

特别的，如果f是凸函数，则局部极小值就是全局极小值。如果该函数还可微，则导数为0的点就是全局极小值点。

实际情况中凸函数是很少的，对于一般函数我们通过迭代的方法，逐步找到最小值，每步迭代的关键就是 **<font color=#FF0000>如何找到当前点邻域内的极小值点</font>** 。根据找邻域内极小值方法的不同，无约束优化方法可分为两类，线搜索和置信域。迭代方法一个重要指标就是收敛速度。下面我们会对每种方法做介绍，并分析其收敛速度。

$$\left\{
  \begin{matrix}
   线搜索\left\{\begin{matrix}最速梯度\\牛顿法\\拟牛顿法\\共轭梯度法\end{matrix} \right.\\
   置信域\left\{\begin{matrix}柯西点\\折线法\\二维搜索\end{matrix} \right.
  \end{matrix}
\right.$$

在详细介绍之前我还想先简要概述一下几种方法，它们之间也有一点共通的地方。

# 2.线搜索

## 最速梯度下降法
